GLM-5 is available to try on Modal.[Get started](https://modal.com/glm-5-endpoint)

# AI infrastructure that   developers love

Run inference, training, and batch processing with sub-second cold
starts, instant autoscaling, and a developer experience that feels
local.

[Get Started](https://modal.com/signup?next=%2Fapps) Contact Us

[![Company logo](data:image/svg+xml,%3csvg%20width='76'%20height='24'%20viewBox='0%200%2076%2024'%20fill='none'%20xmlns='http://www.w3.org/2000/svg'%3e%3cg%20clip-path='url(%23clip0_64_152)'%3e%3cpath%20d='M9.34029%209.7503H4.67015V5.30796H8.42905C8.93023%205.30796%209.34029%204.8979%209.34029%204.39672V0.637817H13.7826V5.30796C13.7826%207.76833%2011.7893%209.7503%209.34029%209.7503ZM4.67015%2010.2059H0V14.6483H3.7589C4.26009%2014.6483%204.67015%2015.0583%204.67015%2015.5595V19.3184H9.11248V14.6483C9.11248%2012.1879%207.11913%2010.2059%204.67015%2010.2059ZM19.6032%209.97811C19.102%209.97811%2018.692%209.56805%2018.692%209.06686V5.30796H14.2496V9.97811C14.2496%2012.4385%2016.243%2014.4204%2018.692%2014.4204H23.3621V9.97811H19.6032ZM9.56811%2019.3184V23.9886H14.0104V20.2297C14.0104%2019.7285%2014.4205%2019.3184%2014.9217%2019.3184H18.6806V14.8761H14.0104C11.5501%2014.8761%209.56811%2016.8694%209.56811%2019.3184Z'%20fill='%23DDFFDC'%20fill-opacity='1'/%3e%3cpath%20d='M53.4788%203.79307H49.0479V0.626483H53.4788V3.79307ZM50.0275%206.4243H47.3621V9.75036H49.6858C50.073%209.75036%2050.392%2010.0693%2050.392%2010.4566V24H53.9003V10.206C53.9003%207.757%2052.317%206.4243%2050.0389%206.4243H50.0275ZM39.3089%200.626483L47.9886%2023.9886H44.298L41.9971%2017.7807H31.1419L28.841%2023.9886H25.1846L33.8642%200.626483H39.3089ZM40.915%2014.8761L36.5752%203.18937L32.2354%2014.8761H40.915ZM62.1812%2021.084L69.3118%2015.457C73.4579%2012.1879%2075.2804%209.90982%2075.2804%206.77741C75.2804%203.64499%2073.2073%200%2066.9539%200C60.7005%200%2056.9074%205.08021%2056.9074%209.75036H60.7005C60.7005%205.53583%2062.5685%202.98434%2066.9539%202.98434C71.3393%202.98434%2071.4874%204.86379%2071.4874%206.81158C71.4874%208.75937%2070.9634%209.76175%2068.9245%2011.4134L56.9757%2021.0726V23.9886H75.7019V21.0726H62.1699L62.1812%2021.084Z'%20fill='%23DDFFDC'%20fill-opacity='1'/%3e%3c/g%3e%3cdefs%3e%3cclipPath%20id='clip0_64_152'%3e%3crect%20width='75.7019'%20height='24'%20fill='white'/%3e%3c/clipPath%3e%3c/defs%3e%3c/svg%3e)](https://allenai.org/)

[![Company logo](https://modal.com/_app/immutable/assets/Lovable.DNrCFD-T.svg)](https://modal.com/blog/lovable-case-study)[![Company logo](https://modal.com/_app/immutable/assets/YouDotCom.V2KoO3lf.svg)](https://you.com/)

[![Company logo](https://modal.com/_app/immutable/assets/Cognition.DodUjy-h.svg)](https://cognition.ai/)

[![Company logo](https://modal.com/_app/immutable/assets/Codegen.ibfW0-BL.svg)](https://codegen.com/)

[![Company logo](data:image/svg+xml,%3csvg%20width='76'%20height='24'%20viewBox='0%200%2076%2024'%20fill='none'%20xmlns='http://www.w3.org/2000/svg'%3e%3cg%20clip-path='url(%23clip0_64_152)'%3e%3cpath%20d='M9.34029%209.7503H4.67015V5.30796H8.42905C8.93023%205.30796%209.34029%204.8979%209.34029%204.39672V0.637817H13.7826V5.30796C13.7826%207.76833%2011.7893%209.7503%209.34029%209.7503ZM4.67015%2010.2059H0V14.6483H3.7589C4.26009%2014.6483%204.67015%2015.0583%204.67015%2015.5595V19.3184H9.11248V14.6483C9.11248%2012.1879%207.11913%2010.2059%204.67015%2010.2059ZM19.6032%209.97811C19.102%209.97811%2018.692%209.56805%2018.692%209.06686V5.30796H14.2496V9.97811C14.2496%2012.4385%2016.243%2014.4204%2018.692%2014.4204H23.3621V9.97811H19.6032ZM9.56811%2019.3184V23.9886H14.0104V20.2297C14.0104%2019.7285%2014.4205%2019.3184%2014.9217%2019.3184H18.6806V14.8761H14.0104C11.5501%2014.8761%209.56811%2016.8694%209.56811%2019.3184Z'%20fill='%23DDFFDC'%20fill-opacity='1'/%3e%3cpath%20d='M53.4788%203.79307H49.0479V0.626483H53.4788V3.79307ZM50.0275%206.4243H47.3621V9.75036H49.6858C50.073%209.75036%2050.392%2010.0693%2050.392%2010.4566V24H53.9003V10.206C53.9003%207.757%2052.317%206.4243%2050.0389%206.4243H50.0275ZM39.3089%200.626483L47.9886%2023.9886H44.298L41.9971%2017.7807H31.1419L28.841%2023.9886H25.1846L33.8642%200.626483H39.3089ZM40.915%2014.8761L36.5752%203.18937L32.2354%2014.8761H40.915ZM62.1812%2021.084L69.3118%2015.457C73.4579%2012.1879%2075.2804%209.90982%2075.2804%206.77741C75.2804%203.64499%2073.2073%200%2066.9539%200C60.7005%200%2056.9074%205.08021%2056.9074%209.75036H60.7005C60.7005%205.53583%2062.5685%202.98434%2066.9539%202.98434C71.3393%202.98434%2071.4874%204.86379%2071.4874%206.81158C71.4874%208.75937%2070.9634%209.76175%2068.9245%2011.4134L56.9757%2021.0726V23.9886H75.7019V21.0726H62.1699L62.1812%2021.084Z'%20fill='%23DDFFDC'%20fill-opacity='1'/%3e%3c/g%3e%3cdefs%3e%3cclipPath%20id='clip0_64_152'%3e%3crect%20width='75.7019'%20height='24'%20fill='white'/%3e%3c/clipPath%3e%3c/defs%3e%3c/svg%3e)](https://allenai.org/)

[![Company logo](https://modal.com/_app/immutable/assets/Lovable.DNrCFD-T.svg)](https://modal.com/blog/lovable-case-study)[![Company logo](https://modal.com/_app/immutable/assets/YouDotCom.V2KoO3lf.svg)](https://you.com/)

[![Company logo](https://modal.com/_app/immutable/assets/Cognition.DodUjy-h.svg)](https://cognition.ai/)

[![Company logo](https://modal.com/_app/immutable/assets/Codegen.ibfW0-BL.svg)](https://codegen.com/)

PROGRAMMABLE INFRA

BUILT FOR PERFORMANCE

ELASTIC GPU SCALING

UNIFIED OBSERVABILITY

Why Modal

## Designed to help AI teams    deploy faster.

### Programmable infra

Define everything in code, no YAML or config files. Keep environment and hardware requirements in sync.

### Built for performance

Launch and scale containers in seconds to keep feedback loops tight and latency low.

### Elastic GPU scaling

Elastic GPU capacity and access to thousands of GPUs across clouds. No quotas or reservations. Scale back to zero when not in use.

### Unified observability

Integrated logging and full visibility into every function, container, and workload.

PRODUCTS

## Powering any ML workload

[**Inference** \\
\\
Deploy and scale inference for LLMs, audio, image/video generation.\\
\\
Learn more](https://modal.com/products/inference) [**Training** \\
\\
Fine-tune open-source models on single or multi-node clusters instantly.\\
\\
Learn more](https://modal.com/products/training) [**Sandboxes** \\
\\
Programmatically scale secure, ephemeral environments for running untrusted code.\\
\\
Learn more](https://modal.com/products/sandboxes) [**Batch** \\
\\
Scale to thousands of containers for batch workloads on-demand.\\
\\
Learn more](https://modal.com/products/batch) [**Notebooks** \\
\\
Collaborate on code and data in real-time with shareable notebooks.\\
\\
Learn more](https://modal.com/products/notebooks)

PLATFORM

## Build on a powerful foundation

From filesystem to runtime, every layer of Modal‚Äôs platform is
engineered to give you the tools to build robust, scalable data
applications.

[Learn More](https://modal.com/products/platform)

#### AI-native runtime

Engineered from the ground up for heavy AI workloads, built for super-fast autoscaling and model initialization and 100x faster than Docker.

#### Built-in storage layer

A globally distributed storage system built for high throughput and low latency. Designed for fast model loading, training data, or other datasets.

#### First-party integrations

Mount your existing cloud buckets, connect to MLOps tools, and send data to your existing telemetry vendors.

#### Multi-cloud capacity pool

Deep multi-cloud capacity with intelligent scheduling ensures you always have the CPUs and GPUs you need without managing input orchestration.

## Built with Modal

[All examples](https://modal.com/docs/examples)

Audio Transcription

LLM Inference

Coding Agents

Computational Biology

Image and Video Inference

[**Transcribe speech in batches with Whisper** \\
\\
Turn audio bytes into text at scale](https://modal.com/docs/examples/batched_whisper)

[**Voice chat with LLMs** \\
\\
Build an interactive voice chat app](https://modal.com/docs/examples/llm-voice-chat)

[**Transcribe speech with Kyutai STT** \\
\\
Stream transcripts at the speed of speech](https://modal.com/docs/examples/streaming_kyutai_stt)

[**Make music** \\
\\
Turn prompts into music with ACE-Step](https://modal.com/docs/examples/generate_music)

[**Fine-tune Whisper on domain vocab** \\
\\
Improve Whisper transcription accuracy on specialized vocabularies with fine-tuning](https://modal.com/docs/examples/fine_tune_asr)

[**Deploy a TTS API with Chatterbox** \\
\\
Serve text-to-speech with Chatterbox to generate natural audio from text](https://modal.com/docs/examples/chatterbox_tts)

## Security and governance

* * *

Team controls

* * *

Battle-tested isolation

* * *

SOC2 & HIPAA

* * *

Data residency controls

[Learn More](https://modal.com/docs/guide/security)

* * *

Team controls

* * *

Battle-tested isolation

* * *

SOC2 & HIPAA

* * *

Data residency controls

[Learn More](https://modal.com/docs/guide/security)

> ‚ÄúWe use Modal to run edge inference with <10ms overhead and batch jobs at large scale. Our team loves the platform for the power and flexibility it gives us.‚Äù

Brian Ichter, Co-founder

> ‚ÄúModal makes it easy to write code that runs on 100s of GPUs in parallel, transcribing podcasts in a fraction of the time.‚Äù

Mike Cohen, Head of Data

[Read Case Study](https://modal.com/blog/substack-case-study)

> ‚ÄúEveryone here loves Modal because it helps us move so much faster. We rely on it to handle massive spikes in volume for evals, RL environments, and MCP servers. Whenever a team asks about compute, we tell them to use Modal.‚Äù

Aakash Sabharwal, VP of Engineering

> ‚ÄúWe've previously managed to break services like GitHub because of our load, so Modal handling our massive scale so smoothly means a lot. We trust Modal to keep up with our growth, and we're excited to build together in the long term.‚Äù

Anton Osika, CEO & Founder

[Read Case Study](https://modal.com/blog/lovable-case-study)

Join Modal's developer community

[Modal Community Slack](https://modal.com/slack)

[![Twitter profile @garrrikkotua](https://pbs.twimg.com/profile_images/1963307212811452416/jDymF0ei.jpg)](https://twitter.com/garrrikkotua/status/1786042460143247506)[Igor Kotua\\
\\
Engineer, The Linux Foundation](https://twitter.com/garrrikkotua/status/1786042460143247506)

If you building AI stuff with Python and haven't tried [@modal](https://x.com/modal) you are missing out big time

[![Twitter profile @calebfahlgren](https://pbs.twimg.com/profile_images/1716604301563289600/YycgFNAn.jpg)](https://twitter.com/calebfahlgren/status/1825733420976124199)[Caleb\\
\\
ML Engineer, Hugging Face](https://twitter.com/calebfahlgren/status/1825733420976124199)

Bullish on [@modal](https://x.com/modal)

\- Great Docs + Examples
\- Healthy Free Plan (30$ free compute / month)
\- Never have to worry about infra / just Python

[![Twitter profile @danrothenberg](https://modal-cdn.com/cdnbot/tmpndzqy7fc_1fe4563b.webp)](https://twitter.com/danrothenberg/status/1835055915516805301)[Daniel Rothenberg\\
\\
Co-founder, Brightband](https://twitter.com/danrothenberg/status/1835055915516805301)

[@modal](https://x.com/modal) continues to be magical... 10 minutes of effort and the \`joblib\`-based parallelism I use to test on my local machine can trivially scale out on the cloud. Makes life so easy!

[![Twitter profile @mattzcarey](https://modal-cdn.com/cdnbot/tmpbisrydal_4d61419e.webp)](https://twitter.com/mattzcarey/status/1806003178691006905)[@mattzcarey.com on blsky\\
\\
AI Engineer, StackOne](https://twitter.com/mattzcarey/status/1806003178691006905)

[@modal](https://x.com/modal) has got a bunch of stuff just worked out

this should be how you deploy python apps. wow

[![Twitter profile @erinselene](https://pbs.twimg.com/profile_images/1595233713536704513/j2d9PYiK.jpg)](https://twitter.com/erinselene/status/1601060264102678528)[Erin Boyle\\
\\
ML Engineer, Tesla](https://twitter.com/erinselene/status/1601060264102678528)

This tool is awesome. So empowering to have your infra needs met with just a couple decorators. Good people, too!

[![Twitter profile @_amankishore](https://modal-cdn.com/aman_kishore.jpg)](https://twitter.com/_amankishore/status/1669845359634575360)[Aman Kishore\\
\\
Research Engineer, Harvey](https://twitter.com/_amankishore/status/1669845359634575360)

If you are still using AWS Lambda instead of [@modal](https://x.com/modal) you're not moving fast enough

[![Twitter profile @jai_chopra](https://pbs.twimg.com/profile_images/1664774588772020225/TlVJPiQu.jpg)](https://twitter.com/jai_chopra/status/1661033887819268096)[Jai Chopra\\
\\
Product, LanceDB](https://twitter.com/jai_chopra/status/1661033887819268096)

Recently built an app on Lambda and just started to use [@modal](https://x.com/modal), the difference is insane! Modal is amazing, virtually no cold start time, onboarding experience is great üöÄ

[![Twitter profile @isidoremiller](https://pbs.twimg.com/profile_images/1679859339073404930/_PB_4LM0.jpg)](https://twitter.com/isidoremiller/status/1645953205480878080)[Izzy Miller\\
\\
DevRel, Hex](https://twitter.com/isidoremiller/status/1645953205480878080)

special shout out to [@modal](https://x.com/modal) and [@\_hex\_tech](https://x.com/_hex_tech) for providing the crucial infrastructure to run this! Modal is the coolest tool I‚Äôve tried in a really long time‚Äî cannnot say enough good things.

[![Twitter profile @dieegosf](https://pbs.twimg.com/profile_images/1623322737836949504/fYVRjQXS.jpg)](https://twitter.com/dieegosf/status/1811018060200874157)[Diego Fernandes\\
\\
Co-founder & CTO, RocketSeat](https://twitter.com/dieegosf/status/1811018060200874157)

Probably one of the best piece of software I'm using this year: [modal.com](https://modal.com/)

[![Twitter profile @marktenenholtz](https://pbs.twimg.com/profile_images/1468741945560289283/YZ3cOr_H.jpg)](https://twitter.com/marktenenholtz/status/1784348202545614937)[Mark Tenenholtz\\
\\
Head of AI, PredeloHQ](https://twitter.com/marktenenholtz/status/1784348202545614937)

I use [@modal](https://x.com/modal) because it brings me joy. There isn't much more to it.

[![Twitter profile @AAAzzam](https://pbs.twimg.com/profile_images/1656519795976687619/abuB5K8p.jpg)](https://twitter.com/AAAzzam/status/1793118336525447302)[Adam Azzam\\
\\
Product, Prefect](https://twitter.com/AAAzzam/status/1793118336525447302)

feels weird at this point to use anything else than [@modal](https://x.com/modal) for this ‚Äî absolutely the GOAT of dynamic sandboxes

[![Twitter profile @MarkNeumannnn](https://pbs.twimg.com/profile_images/1363023976868417538/M-l9jMWz_400x400.jpg)](https://x.com/MarkNeumannnn/status/1959775622772982204)[Mark Neumann\\
\\
Head of ML, Orbital Materials](https://x.com/MarkNeumannnn/status/1959775622772982204)

Used [@modal](https://twitter.com/modal?ref_src=twsrc%5Etfw) for the first time today - immediate "oh, this is how backends should work" moment, similar to using Vercel for the first time for frontend deployments.

[![Twitter profile @remilouf](https://pbs.twimg.com/profile_images/1570519314142318595/PJGWEkfu.jpg)](https://twitter.com/remilouf/status/1845742524997963800)[R√©mi üìé\\
\\
Co-founder & CEO, .txt](https://twitter.com/remilouf/status/1845742524997963800)

Nothing beats [@modal](https://x.com/modal) when it comes to deploying a quick POC

[![Twitter profile @moinnadeem](https://pbs.twimg.com/profile_images/1252656439149105156/dU40XVKb.jpg)](https://twitter.com/moinnadeem/status/1814729047181832484)[Moin Nadeem\\
\\
Co-founder, Phonic](https://twitter.com/moinnadeem/status/1814729047181832484)

I've realized [@modal](https://x.com/modal) is actually a great fit for ML training pipelines.

If you're running model-based evals, why not just call a serverless Modal function and have it evaluate your model on a separate worker GPU? This makes evaluation during training really easy.

[![Twitter profile @holdenmatt](https://pbs.twimg.com/profile_images/1675120765761654784/jJz2F_r9.jpg)](https://twitter.com/holdenmatt/status/1797695485479915795)[Matt Holden\\
\\
Founder](https://twitter.com/holdenmatt/status/1797695485479915795)

Late to the party, but finally playing with [@modal](https://x.com/modal) to run some backend jobs.

DX is sooo nice (compared to Docker, Cloud Run, Lambda, etc). Just decorate a Python function and deploy. And it's fast! Love it.

[![Twitter profile @garrrikkotua](https://pbs.twimg.com/profile_images/1963307212811452416/jDymF0ei.jpg)](https://twitter.com/garrrikkotua/status/1786042460143247506)[Igor Kotua\\
\\
Engineer, The Linux Foundation](https://twitter.com/garrrikkotua/status/1786042460143247506)

If you building AI stuff with Python and haven't tried [@modal](https://x.com/modal) you are missing out big time

[![Twitter profile @calebfahlgren](https://pbs.twimg.com/profile_images/1716604301563289600/YycgFNAn.jpg)](https://twitter.com/calebfahlgren/status/1825733420976124199)[Caleb\\
\\
ML Engineer, Hugging Face](https://twitter.com/calebfahlgren/status/1825733420976124199)

Bullish on [@modal](https://x.com/modal)

\- Great Docs + Examples
\- Healthy Free Plan (30$ free compute / month)
\- Never have to worry about infra / just Python

[![Twitter profile @danrothenberg](https://modal-cdn.com/cdnbot/tmpndzqy7fc_1fe4563b.webp)](https://twitter.com/danrothenberg/status/1835055915516805301)[Daniel Rothenberg\\
\\
Co-founder, Brightband](https://twitter.com/danrothenberg/status/1835055915516805301)

[@modal](https://x.com/modal) continues to be magical... 10 minutes of effort and the \`joblib\`-based parallelism I use to test on my local machine can trivially scale out on the cloud. Makes life so easy!

[![Twitter profile @mattzcarey](https://modal-cdn.com/cdnbot/tmpbisrydal_4d61419e.webp)](https://twitter.com/mattzcarey/status/1806003178691006905)[@mattzcarey.com on blsky\\
\\
AI Engineer, StackOne](https://twitter.com/mattzcarey/status/1806003178691006905)

[@modal](https://x.com/modal) has got a bunch of stuff just worked out

this should be how you deploy python apps. wow

[![Twitter profile @erinselene](https://pbs.twimg.com/profile_images/1595233713536704513/j2d9PYiK.jpg)](https://twitter.com/erinselene/status/1601060264102678528)[Erin Boyle\\
\\
ML Engineer, Tesla](https://twitter.com/erinselene/status/1601060264102678528)

This tool is awesome. So empowering to have your infra needs met with just a couple decorators. Good people, too!

[![Twitter profile @_amankishore](https://modal-cdn.com/aman_kishore.jpg)](https://twitter.com/_amankishore/status/1669845359634575360)[Aman Kishore\\
\\
Research Engineer, Harvey](https://twitter.com/_amankishore/status/1669845359634575360)

If you are still using AWS Lambda instead of [@modal](https://x.com/modal) you're not moving fast enough

[![Twitter profile @jai_chopra](https://pbs.twimg.com/profile_images/1664774588772020225/TlVJPiQu.jpg)](https://twitter.com/jai_chopra/status/1661033887819268096)[Jai Chopra\\
\\
Product, LanceDB](https://twitter.com/jai_chopra/status/1661033887819268096)

Recently built an app on Lambda and just started to use [@modal](https://x.com/modal), the difference is insane! Modal is amazing, virtually no cold start time, onboarding experience is great üöÄ

[![Twitter profile @isidoremiller](https://pbs.twimg.com/profile_images/1679859339073404930/_PB_4LM0.jpg)](https://twitter.com/isidoremiller/status/1645953205480878080)[Izzy Miller\\
\\
DevRel, Hex](https://twitter.com/isidoremiller/status/1645953205480878080)

special shout out to [@modal](https://x.com/modal) and [@\_hex\_tech](https://x.com/_hex_tech) for providing the crucial infrastructure to run this! Modal is the coolest tool I‚Äôve tried in a really long time‚Äî cannnot say enough good things.

[![Twitter profile @dieegosf](https://pbs.twimg.com/profile_images/1623322737836949504/fYVRjQXS.jpg)](https://twitter.com/dieegosf/status/1811018060200874157)[Diego Fernandes\\
\\
Co-founder & CTO, RocketSeat](https://twitter.com/dieegosf/status/1811018060200874157)

Probably one of the best piece of software I'm using this year: [modal.com](https://modal.com/)

[![Twitter profile @marktenenholtz](https://pbs.twimg.com/profile_images/1468741945560289283/YZ3cOr_H.jpg)](https://twitter.com/marktenenholtz/status/1784348202545614937)[Mark Tenenholtz\\
\\
Head of AI, PredeloHQ](https://twitter.com/marktenenholtz/status/1784348202545614937)

I use [@modal](https://x.com/modal) because it brings me joy. There isn't much more to it.

[![Twitter profile @AAAzzam](https://pbs.twimg.com/profile_images/1656519795976687619/abuB5K8p.jpg)](https://twitter.com/AAAzzam/status/1793118336525447302)[Adam Azzam\\
\\
Product, Prefect](https://twitter.com/AAAzzam/status/1793118336525447302)

feels weird at this point to use anything else than [@modal](https://x.com/modal) for this ‚Äî absolutely the GOAT of dynamic sandboxes

[![Twitter profile @MarkNeumannnn](https://pbs.twimg.com/profile_images/1363023976868417538/M-l9jMWz_400x400.jpg)](https://x.com/MarkNeumannnn/status/1959775622772982204)[Mark Neumann\\
\\
Head of ML, Orbital Materials](https://x.com/MarkNeumannnn/status/1959775622772982204)

Used [@modal](https://twitter.com/modal?ref_src=twsrc%5Etfw) for the first time today - immediate "oh, this is how backends should work" moment, similar to using Vercel for the first time for frontend deployments.

[![Twitter profile @remilouf](https://pbs.twimg.com/profile_images/1570519314142318595/PJGWEkfu.jpg)](https://twitter.com/remilouf/status/1845742524997963800)[R√©mi üìé\\
\\
Co-founder & CEO, .txt](https://twitter.com/remilouf/status/1845742524997963800)

Nothing beats [@modal](https://x.com/modal) when it comes to deploying a quick POC

[![Twitter profile @moinnadeem](https://pbs.twimg.com/profile_images/1252656439149105156/dU40XVKb.jpg)](https://twitter.com/moinnadeem/status/1814729047181832484)[Moin Nadeem\\
\\
Co-founder, Phonic](https://twitter.com/moinnadeem/status/1814729047181832484)

I've realized [@modal](https://x.com/modal) is actually a great fit for ML training pipelines.

If you're running model-based evals, why not just call a serverless Modal function and have it evaluate your model on a separate worker GPU? This makes evaluation during training really easy.

[![Twitter profile @holdenmatt](https://pbs.twimg.com/profile_images/1675120765761654784/jJz2F_r9.jpg)](https://twitter.com/holdenmatt/status/1797695485479915795)[Matt Holden\\
\\
Founder](https://twitter.com/holdenmatt/status/1797695485479915795)

Late to the party, but finally playing with [@modal](https://x.com/modal) to run some backend jobs.

DX is sooo nice (compared to Docker, Cloud Run, Lambda, etc). Just decorate a Python function and deploy. And it's fast! Love it.

## Ship your first app in minutes.

[Get Started](https://modal.com/signup)

$30 / month free compute

[![Modal logo](data:image/svg+xml,%3csvg%20width='368'%20height='192'%20viewBox='0%200%20368%20192'%20fill='none'%20xmlns='http://www.w3.org/2000/svg'%3e%3cpath%20d='M148.873%204L183.513%2064L111.922%20188C110.492%20190.47%20107.853%20192%20104.993%20192H40.3325C38.9025%20192%2037.5325%20191.62%2036.3325%20190.93C35.1325%20190.24%2034.1226%20189.24%2033.4026%20188L1.0725%20132C-0.3575%20129.53%20-0.3575%20126.48%201.0725%20124L70.3625%204C71.0725%202.76%2072.0925%201.76001%2073.2925%201.07001C74.4925%200.380007%2075.8625%200%2077.2925%200H141.952C144.812%200%20147.453%201.53%20148.883%204H148.873ZM365.963%20124L296.672%204C295.962%202.76%20294.943%201.76001%20293.743%201.07001C292.543%200.380007%20291.173%200%20289.743%200H225.083C222.223%200%20219.583%201.53%20218.153%204L183.513%2064L255.103%20188C256.533%20190.47%20259.173%20192%20262.033%20192H326.693C328.122%20192%20329.492%20191.62%20330.693%20190.93C331.893%20190.24%20332.902%20189.24%20333.622%20188L365.953%20132C367.383%20129.53%20367.383%20126.48%20365.953%20124H365.963Z'%20fill='%2362DE61'/%3e%3cpath%20d='M109.623%2064H183.523L148.883%204C147.453%201.53%20144.813%200%20141.953%200H77.2925C75.8625%200%2074.4925%200.380007%2073.2925%201.07001L109.623%2064Z'%20fill='url(%23paint0_linear_342_139)'/%3e%3cpath%20d='M109.623%2064L73.2925%201.07001C72.0925%201.76001%2071.0825%202.76%2070.3625%204L1.0725%20124C-0.3575%20126.48%20-0.3575%20129.52%201.0725%20132L33.4026%20188C34.1126%20189.24%2035.1325%20190.24%2036.3325%20190.93L109.613%2064H109.623Z'%20fill='url(%23paint1_linear_342_139)'/%3e%3cpath%20d='M183.513%2064H109.613L36.3325%20190.93C37.5325%20191.62%2038.9025%20192%2040.3325%20192H104.993C107.853%20192%20110.492%20190.47%20111.922%20188L183.513%2064Z'%20fill='%2309AF58'/%3e%3cpath%20d='M365.963%20132C366.673%20130.76%20367.033%20129.38%20367.033%20128H294.372L258.042%20190.93C259.242%20191.62%20260.612%20192%20262.042%20192H326.703C329.563%20192%20332.202%20190.47%20333.632%20188L365.963%20132Z'%20fill='%2309AF58'/%3e%3cpath%20d='M225.083%200C223.653%200%20222.283%200.380007%20221.083%201.07001L294.362%20128H367.023C367.023%20126.62%20366.663%20125.24%20365.953%20124L296.672%204C295.242%201.53%20292.603%200%20289.743%200H225.073H225.083Z'%20fill='url(%23paint2_linear_342_139)'/%3e%3cpath%20d='M258.033%20190.93L294.362%20128L221.083%201.07001C219.883%201.76001%20218.873%202.76%20218.153%204L183.513%2064L255.103%20188C255.813%20189.24%20256.833%20190.24%20258.033%20190.93Z'%20fill='url(%23paint3_linear_342_139)'/%3e%3cdefs%3e%3clinearGradient%20id='paint0_linear_342_139'%20x1='155.803'%20y1='80'%20x2='101.003'%20y2='-14.93'%20gradientUnits='userSpaceOnUse'%3e%3cstop%20stop-color='%23BFF9B4'/%3e%3cstop%20offset='1'%20stop-color='%2380EE64'/%3e%3c/linearGradient%3e%3clinearGradient%20id='paint1_linear_342_139'%20x1='8.62251'%20y1='174.93'%20x2='100.072'%20y2='16.54'%20gradientUnits='userSpaceOnUse'%3e%3cstop%20stop-color='%2380EE64'/%3e%3cstop%20offset='0.18'%20stop-color='%237BEB63'/%3e%3cstop%20offset='0.36'%20stop-color='%236FE562'/%3e%3cstop%20offset='0.55'%20stop-color='%235ADA60'/%3e%3cstop%20offset='0.74'%20stop-color='%233DCA5D'/%3e%3cstop%20offset='0.93'%20stop-color='%2318B759'/%3e%3cstop%20offset='1'%20stop-color='%2309AF58'/%3e%3c/linearGradient%3e%3clinearGradient%20id='paint2_linear_342_139'%20x1='340.243'%20y1='143.46'%20x2='248.793'%20y2='-14.93'%20gradientUnits='userSpaceOnUse'%3e%3cstop%20stop-color='%23BFF9B4'/%3e%3cstop%20offset='1'%20stop-color='%2380EE64'/%3e%3c/linearGradient%3e%3clinearGradient%20id='paint3_linear_342_139'%20x1='284.822'%20y1='175.47'%20x2='193.372'%20y2='17.0701'%20gradientUnits='userSpaceOnUse'%3e%3cstop%20stop-color='%2380EE64'/%3e%3cstop%20offset='0.18'%20stop-color='%237BEB63'/%3e%3cstop%20offset='0.36'%20stop-color='%236FE562'/%3e%3cstop%20offset='0.55'%20stop-color='%235ADA60'/%3e%3cstop%20offset='0.74'%20stop-color='%233DCA5D'/%3e%3cstop%20offset='0.93'%20stop-color='%2318B759'/%3e%3cstop%20offset='1'%20stop-color='%2309AF58'/%3e%3c/linearGradient%3e%3c/defs%3e%3c/svg%3e)](https://modal.com/)

¬© Modal 2026

Products

[Modal Inference](https://modal.com/products/inference)

[Modal Sandboxes](https://modal.com/products/sandboxes)

[Modal Training](https://modal.com/products/training)

[Modal Notebooks](https://modal.com/products/notebooks)

[Modal Batch](https://modal.com/products/batch)

[Modal Core Platform](https://modal.com/products/platform)

Resources

[Documentation](https://modal.com/docs/guide)

[Pricing](https://modal.com/pricing)

[Slack Community](https://modal.com/slack)

[Articles](https://modal.com/articles)

[GPU Glossary](https://modal.com/gpu-glossary)

[LLM Engine Advisor](https://modal.com/llm-almanac)

[Model Library](https://modal.com/library)

Popular Examples

[Serve your own LLM API](https://modal.com/docs/examples/llm_inference)

[Create custom art of your pet](https://modal.com/docs/examples/diffusers_lora_finetune)

[Analyze Parquet files from S3 with DuckDB](https://modal.com/docs/examples/s3_bucket_mount)

[Run hundreds of LoRAs from one app](https://modal.com/docs/examples/cloud_bucket_mount_loras)

[Finetune an LLM to replace your CEO](https://modal.com/docs/examples/llm-finetuning)

Company

[About](https://modal.com/company)

[Blog](https://modal.com/blog)

[Careers](https://modal.com/careers)

[Events](https://modal.com/events)

[Privacy Policy](https://modal.com/legal/privacy-policy)

[Security & Privacy](https://modal.com/docs/guide/security)

[Terms](https://modal.com/legal/terms)

¬© Modal 2026